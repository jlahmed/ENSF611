{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Jubayer Ahmed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262200 <class 'pandas.core.frame.DataFrame'>\n",
      "4600 <class 'pandas.core.series.Series'>\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "X,y = load_spam()\n",
    "print(X.size, type(X))\n",
    "print(y.size, type(y))\n",
    "print(X.dtypes)\n",
    "print(y.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(X.isnull().sum().sum())\n",
    "print(y.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_small, _, y_small, _ = train_test_split(X, y, train_size = 0.05, stratify=y, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Trained Data Size  Training Score  Validation score\n",
      "Using all features             262200        0.933913          0.931304\n",
      "Using two features               9200        0.619420          0.605217\n",
      "Using 5% of data                13110        0.941860          0.948276\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Using X,y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=0)\n",
    "log = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "full_t = log.score(X_train, y_train)\n",
    "full_v = log.score(X_test, y_test)\n",
    "\n",
    "#Using only first two columns\n",
    "X_t, X_v, y_t, y_v = train_test_split(X.iloc[:,0:2], y, stratify=y,random_state=0)\n",
    "l = LogisticRegression(max_iter=2000).fit(X_t, y_t)\n",
    "two_t = l.score(X_t, y_t)\n",
    "two_v = l.score(X_v, y_v)\n",
    "\n",
    "#Using 5% of data\n",
    "\n",
    "X_small5, X_val, y_small5, y_val = train_test_split(X_small, y_small, stratify=y_small, random_state=0)\n",
    "lg = LogisticRegression(max_iter=2000).fit(X_small5, y_small5)\n",
    "small_t = lg.score(X_small5, y_small5)\n",
    "small_v = lg.score(X_val, y_val)\n",
    "\n",
    "data = {\"Trained Data Size\": [X.size, X.iloc[:,0:2].size, X_small.size], \"Training Score\": [full_t, two_t, small_t], \"Validation score\": [full_v, two_v, small_v]}\n",
    "results = pd.DataFrame(data, index=[\"Using all features\", \"Using two features\", \"Using 5% of data\"])\n",
    "print(results)\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "\n",
    "\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "1. We can see that when we are using only the first two features, we get low training and validation scores indicating that our model is not not performing well. This means that our model would benefit from using more features. We have a low variance since the training and validation scores are close but high bias since they are not predicting the unseen data well. This indicates an underfit.\n",
    "\n",
    "When using all features, we can see that the training and validation are high whether we are using 5% of the data or the entire data. This means that our model is performing well with both low and high sample size when using all the features. Our model is fitting the data well. It is perforiming well on the training set and on unseen data.\n",
    "\n",
    "2. A false positive would be identifying a non-spam email as spam wheras a false negative would be identifying a spam email as non spam. A false positive is worse than a false negative because the false negative can easily be deleted manually. However in the event of a false positive, you may have an important email that will go to the junk folder and will remain unseen by the person (for example job interview email)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code? \n",
    "2. In what order did you complete the steps?\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not? \n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. From the note/lab material\n",
    "2. I did in order they are posted\n",
    "3. I did not use AI\n",
    "4.  I had difficulty writing the code. I was able to overcome it by looking at the code snipets from class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8240 <class 'pandas.core.frame.DataFrame'>\n",
      "1030 <class 'pandas.core.series.Series'>\n",
      "cement    float64\n",
      "slag      float64\n",
      "ash       float64\n",
      "water     float64\n",
      "splast    float64\n",
      "coarse    float64\n",
      "fine      float64\n",
      "age         int64\n",
      "dtype: object\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "X, y = load_concrete()\n",
    "print(X.size, type(X))\n",
    "print(y.size, type(y))\n",
    "print(X.dtypes)\n",
    "print(y.dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "print(X.isnull().sum().sum())\n",
    "print(y.isna().sum().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "# Note: for any random state parameters, you can use random_state = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "970c038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "y_pred_val = model.predict(X_val)\n",
    "y_pred_train = model.predict(X_train)\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_val = mean_squared_error(y_val, y_pred_val)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_val = r2_score(y_val, y_pred_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Train  Validation\n",
      "MSE  111.358439   95.904136\n",
      "R2     0.610823    0.623414\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame({'Train': [mse_train, r2_train], 'Validation' : [mse_val, r2_val]}, index=[\"MSE\", \"R2\"])\n",
    "print(results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
    "    No because the r2 value is a lot lower than 1 for both the training and validation scores. This indicates high bias and underfit (too simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "2. In what order did you complete the steps?In the steps they are posted\n",
    "3. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "4. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "1. I looked up how to run the mse and r2 commands on chatGPT\n",
    "2. In the steps they are posted\n",
    "3. I typed this into chatGPT: sklearn metric r2 score and mean square error \n",
    "4. No challenges, it was pretty straight forward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "We can see that although sample size is an important metric, the quality of the sample is equaly (if not more) important. It is important for our data to be representative (have sufficient features) of the unseen data. This is why the 5% sample size in question 1 resulted in a better model than when using only the first two columns (features) which lead to a high bias (underfitted model). When evaluating a model, it is important to look at many indicators to arrive to a conclusion. For example, looking at the mean squarred error without the r2 score could be missleading because although the MSE may be low, it might be high when compared to the data. \n",
    "\n",
    "It is important to note that it is important to train the model well but not to the extent of overtraining it where the validation score starts to drop and cause high variance. It is also important to train the model enough to avoid high bias which would cause the model to perform badly on unseen data. We want to maintain a balance where the training and validation scores are high and the validation score is approaching the training score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "I liked that we were asked to discuss our answers which enforced the learning. It made me realize the true value of the class. I realize that it is not about just running comands. This is also motivates me to keep learning now that I understand the value of the class better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for lasso: \n",
      "             Training Score  Validation Score\n",
      "alpha=0.01        0.610823          0.623429\n",
      "alpha=0.1         0.610821          0.623562\n",
      "alpha=1           0.610609          0.624669\n",
      "alpha=10          0.604314          0.626774\n",
      "alpha=100         0.467576          0.507413\n",
      "\n",
      "Results for ridge: \n",
      "             Training Score  Validation Score\n",
      "alpha=0.01        0.610823          0.623429\n",
      "alpha=0.1         0.610821          0.623562\n",
      "alpha=1           0.610609          0.624669\n",
      "alpha=10          0.604314          0.626774\n",
      "alpha=100         0.467576          0.507413\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "lasso001 = Lasso(alpha=0.01).fit(X_train, y_train)\n",
    "lasso01 = Lasso(alpha=0.1).fit(X_train, y_train)\n",
    "lasso1 = Lasso(alpha=1).fit(X_train, y_train)\n",
    "lasso10 = Lasso(alpha=10).fit(X_train, y_train)\n",
    "lasso100 = Lasso(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "ridge001 = Ridge(alpha=0.01).fit(X_train, y_train)\n",
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "ridge1 = Ridge(alpha=1).fit(X_train, y_train)\n",
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "ridge100 = Ridge(alpha=100).fit(X_train, y_train)\n",
    "\n",
    "data = {\"Training Score\": [lasso001.score(X_train, y_train), lasso01.score(X_train, y_train), lasso1.score(X_train, y_train), lasso10.score(X_train, y_train),\n",
    "                           lasso100.score(X_train, y_train)], \"Validation Score\": [lasso001.score(X_val, y_val), lasso01.score(X_val, y_val),lasso1.score(X_val, y_val),\n",
    "                                                                                   lasso10.score(X_val, y_val), lasso100.score(X_val, y_val)]}\n",
    "results = pd.DataFrame(data, index=[\"alpha=0.01\", \"alpha=0.1\", \"alpha=1\", \"alpha=10\",\"alpha=100\"])\n",
    "\n",
    "data1 = {\"Training Score\": [ridge001.score(X_train, y_train), ridge01.score(X_train, y_train), ridge1.score(X_train, y_train), ridge10.score(X_train, y_train),\n",
    "                           ridge100.score(X_train, y_train)], \"Validation Score\": [ridge001.score(X_val, y_val), ridge01.score(X_val, y_val),ridge1.score(X_val, y_val),\n",
    "                                                                                   ridge10.score(X_val, y_val), ridge100.score(X_val, y_val)]}\n",
    "results1 = pd.DataFrame(data, index=[\"alpha=0.01\", \"alpha=0.1\", \"alpha=1\", \"alpha=10\",\"alpha=100\"])\n",
    "\n",
    "print(\"Results for lasso: \\n\", results)\n",
    "print(\"\\nResults for ridge: \\n\", results1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "We can see that varying alpha (L1 regularization in lasso and L2 in ridge) does not impact the outcome of the training and validation scores as they remain consistently low. This suggests that there is no one feature that is more important in predicting the outcome. Reducing some coefficient (L2) or eliminating some coefficient (L1) does not help us create a good model. This suggests that our data follows a standard linear regression model more closely."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
